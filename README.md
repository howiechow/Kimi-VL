# Kimi-VL

**Kimi-VL** is an efficient open-source multimodal model developed by the Moonshot AI Kimi Team, capable of recognizing and understanding high-resolution images and lengthy text contexts.

## News
- **2025-04-11**: ðŸ”¥ We release **Kimi-VL-Thinking**, a 2.8B parameter model enhanced with long CoT reasoning capabilities!
- **2025-04-09**: ðŸ”¥ **Kimi-VL** is released!

## Model Introduction

Kimi-VL is a Mixture-of-Experts (MoE) based vision-language model built on Moonshot AI's Kimi language model. It leverages a native-context multimodal LLM design with efficient processing of high-resolution images and long contexts.

For more details, please refer to the original repository.

---

## Related Projects

1. related project [Qwen2.5-VL](https://github.com/QwenLM/Qwen2.5-VL)
2. related project [DeepSeek-VL2](https://github.com/deepseek-ai/DeepSeek-VL2)
3. related project [Aria](https://github.com/rhymes-ai/Aria)